# -*- coding: utf-8 -*-
"""number plate reconization

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mayJv3crzn3gDgOZbQDo1ty-Cz6bQVjZ
"""

!pip install --upgrade pip
!pip install ultralytics==8.0.200
!pip install easyocr
!pip install opencv-python-headless==4.7.0.72
!pip install matplotlib

!pip uninstall -y numpy
!pip cache purge
!pip install numpy==1.26.4 opencv-python-headless==4.9.0.80 ultralytics==8.2.50 easyocr matplotlib --upgrade --no-cache-dir --force-reinstall

import numpy as np, cv2, ultralytics, easyocr, matplotlib
print("NumPy:", np.__version__)
print("OpenCV:", cv2.__version__)
print("Ultralytics:", ultralytics.__version__)
print("EasyOCR imported successfully!")

import os, signal, time
print("Environment ready. Restarting runtime to finalize setup...")
time.sleep(2)
os.kill(os.getpid(), signal.SIGKILL)

import numpy as np, cv2, torch
from ultralytics import YOLO
import easyocr

print("NumPy:", np.__version__)
print("OpenCV:", cv2.__version__)
print("Torch:", torch.__version__, "CUDA available:", torch.cuda.is_available())
print("All imports working fine!")

from google.colab import files
uploaded = files.upload()
video_path = list(uploaded.keys())[0]
print("Uploaded video:", video_path)

import torch
import ultralytics
torch.serialization.add_safe_globals([
    ultralytics.nn.modules.block.SPPF,
    ultralytics.nn.modules.block.Bottleneck,
    ultralytics.nn.modules.block.Conv,
    ultralytics.nn.modules.block.C2f,
])

from ultralytics import YOLO

model = YOLO("yolov8n.pt", task="detect")

print("YOLOv8 model loaded successfully ")

!pip install torch==2.5.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

import cv2
import torch
from ultralytics import YOLO
import easyocr
import time

model = YOLO("yolov8n.pt", task="detect")

reader = easyocr.Reader(['en'])

video_path = "/content/sample.mp4"
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print("Error: Could not open video.")
else:
    print("Video loaded successfully!")
output_path = "/content/output_detection.mp4"
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
fps = int(cap.get(cv2.CAP_PROP_FPS))
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

frame_count = 0
start_time = time.time()

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    results = model(frame)

    for result in results:
        boxes = result.boxes.xyxy.cpu().numpy()
        for (x1, y1, x2, y2) in boxes[:, :4]:
            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])
            plate_crop = frame[y1:y2, x1:x2]

            ocr_results = reader.readtext(plate_crop)
            text = ""
            if len(ocr_results) > 0:
                text = ocr_results[0][-2]

            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, text, (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)

    out.write(frame)
    frame_count += 1

cap.release()
out.release()

print(f"Processing completed! Saved output video at: {output_path}")
print(f"Total frames processed: {frame_count}")
print(f"Time taken: {time.time() - start_time:.2f} seconds")

from google.colab import files
uploaded = files.upload()

!ls /content

!pip install ultralytics opencv-python-headless easyocr -q
import cv2
import torch
from ultralytics import YOLO
import easyocr
import time
from google.colab.patches import cv2_imshow

torch.serialization.add_safe_globals([torch.nn.modules.conv.Conv2d])
model = YOLO("yolov8n.pt")
print("YOLOv8 model loaded successfully!")
reader = easyocr.Reader(['en'])
print("EasyOCR initialized successfully!")

video_path = "/content/videoplayback.mp4"
output_path = "/content/output_detection.mp4"

cap = cv2.VideoCapture(video_path)
if not cap.isOpened():
    raise Exception("Could not open video file. Check your path or file format.")

fps = int(cap.get(cv2.CAP_PROP_FPS))
width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

frame_count = 0
start_time = time.time()

print(" Processing started...")
while True:
    ret, frame = cap.read()
    if not ret:
        break

    frame_count += 1

    results = model(frame, verbose=False)

    annotated_frame = results[0].plot()

    out.write(annotated_frame)

cap.release()
out.release()

end_time = time.time()
print(f"Processing completed! Saved output video at: {output_path}")
print(f"Total frames processed: {frame_count}")
print(f"Time taken: {end_time - start_time:.2f} seconds")

cap_out = cv2.VideoCapture(output_path)
ret, sample_frame = cap_out.read()
if ret:
    print("ðŸ“¸ Showing a sample frame from the output video:")
    cv2_imshow(sample_frame)
cap_out.release()

"""gggg

"""

!pip install -q ultralytics easyocr opencv-python-headless pandas tqdm

import os, time, csv, shutil, math
from google.colab import files
from ultralytics import YOLO
import torch, importlib
import cv2
import numpy as np
import easyocr
from tqdm import tqdm
import pandas as pd

vehicle_model_path = "yolov8n.pt"
plate_model_path = "/content/best.pt"

output_video_path = "/content/output_car_plate_ocr.mp4"
csv_output_path = "/content/detections.csv"

try:
    nn_tasks = importlib.import_module("ultralytics.nn.tasks")
    torch.serialization.add_safe_globals([nn_tasks.DetectionModel, torch.nn.modules.conv.Conv2d])
except Exception:
    pass

print("Loading models...")
vehicle_model = YOLO(vehicle_model_path)
plate_model = YOLO(plate_model_path)
print("Models loaded.")
reader = easyocr.Reader(['en'], gpu=torch.cuda.is_available())
print("EasyOCR initialized (gpu=%s)." % torch.cuda.is_available())

existing_mp4s = [f for f in os.listdir("/content") if f.lower().endswith(".mp4")]
if len(existing_mp4s) > 0:
    print("Found mp4 files in /content:", existing_mp4s)
    if "videoplayback.mp4" in existing_mp4s:
        video_path = "/content/videoplayback.mp4"
    else:
        video_path = os.path.join("/content", existing_mp4s[0])
    print("Using video:", video_path)
else:
    print("No mp4 found in /content. Please upload your video file now.")
    uploaded = files.upload()
    video_path = list(uploaded.keys())[0]
    video_path = os.path.join("/content", video_path)
    print("Uploaded and using:", video_path)
cap_test = cv2.VideoCapture(video_path)
if not cap_test.isOpened():
    raise RuntimeError(f"Could not open video file: {video_path}")
cap_test.release()

cap = cv2.VideoCapture(video_path)
fps = cap.get(cv2.CAP_PROP_FPS) or 25.0
w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
writer = cv2.VideoWriter(output_video_path, fourcc, fps, (w, h))

csv_rows = []
csv_rows.append(["frame", "time_seconds", "plate_text", "plate_confidence", "car_box", "plate_box_in_frame"])

frame_idx = 0
start_time = time.time()

def preprocess_plate_for_ocr(img):

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    h0 = 64
    if gray.shape[0] != h0:
        scale = h0 / max(1, gray.shape[0])
        new_w = max(32, int(gray.shape[1] * scale))
        gray = cv2.resize(gray, (new_w, h0))

    gray = cv2.equalizeHist(gray)
    return gray

print("Processing frames... (this may take a while depending on video length)")
pbar = tqdm(total=int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0))
while True:
    ret, frame = cap.read()
    if not ret:
        break
    frame_idx += 1
    pbar.update(1)
    results = vehicle_model(frame, verbose=False)
    res = results[0]
    if hasattr(res, "boxes") and len(res.boxes) > 0:
        for i,box in enumerate(res.boxes):
            conf = float(box.conf[0]) if hasattr(box, "conf") else None
            cls = int(box.cls[0]) if hasattr(box, "cls") else None
            label = vehicle_model.names[cls] if cls is not None and cls < len(vehicle_model.names) else str(cls)
            if label.lower() not in ["car","truck","bus","motorbike","motorcycle","vehicle","van"]:
                continue

            x1,y1,x2,y2 = map(int, box.xyxy[0])
            x1,y1 = max(0,x1), max(0,y1)
            x2,y2 = min(w-1,x2), min(h-1,y2)
            if x2-x1 < 8 or y2-y1 < 8:
                continue

            car_crop = frame[y1:y2, x1:x2].copy()

            try:
                plate_results = plate_model(car_crop, verbose=False)
            except Exception as e:

                plate_results = []

            plate_text_found = ""
            plate_confidence = 0.0
            plate_box_in_frame = None
            if plate_results and len(plate_results) > 0:
                pres = plate_results[0]
                if hasattr(pres, "boxes") and len(pres.boxes) > 0:

                    best_pbox = None
                    best_pconf = -1.0
                    for pb in pres.boxes:
                        pconf = float(pb.conf[0]) if hasattr(pb, "conf") else 0.0
                        if pconf > best_pconf:
                            best_pconf = pconf
                            best_pbox = pb
                    if best_pbox is not None:
                        px1,py1,px2,py2 = map(int, best_pbox.xyxy[0])

                        plate_box_in_frame = (x1+px1, y1+py1, x1+px2, y1+py2)

                        px1b, py1b, px2b, py2b = max(0,px1), max(0,py1), min(car_crop.shape[1]-1,px2), min(car_crop.shape[0]-1,py2)
                        if px2b-px1b > 5 and py2b-py1b > 5:
                            plate_crop = car_crop[py1b:py2b, px1b:px2b].copy()
                            plate_proc = preprocess_plate_for_ocr(plate_crop)

                            try:
                                ocr_res = reader.readtext(plate_proc, detail=1)

                                best_text, best_score = "", 0.0
                                for o in ocr_res:

                                    txt = o[1].strip()
                                    score = float(o[2]) if len(o) > 2 else 0.0

                                    cleaned = "".join([c for c in txt if c.isalnum()]).upper()
                                    if score > best_score and len(cleaned) >= 4:
                                        best_text = cleaned
                                        best_score = score
                                if best_text == "" and len(ocr_res) > 0:

                                    best_text = "".join([c for c in ocr_res[0][1] if c.isalnum()]).upper()
                                    best_score = float(ocr_res[0][2])
                                plate_text_found = best_text
                                plate_confidence = best_score
                            except Exception as e:
                                plate_text_found = ""
                                plate_confidence = 0.0


            cv2.rectangle(frame, (x1,y1), (x2,y2), (0,200,0), 2)
            cv2.putText(frame, f"{label}", (x1, max(15,y1-8)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,200,0), 2)


            if plate_box_in_frame is not None:
                bx1,by1,bx2,by2 = plate_box_in_frame
                cv2.rectangle(frame, (bx1,by1), (bx2,by2), (0,255,255), 2)
                txt = plate_text_found if plate_text_found else "Plate?"
                cv2.putText(frame, f"{txt} {plate_confidence:.2f}", (bx1, max(15,by1-8)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2)

                tsec = frame_idx / fps
                csv_rows.append([frame_idx, round(tsec,3), plate_text_found, round(plate_confidence,4), f"{x1,y1,x2,y2}", f"{bx1,by1,bx2,by2}"])

    writer.write(frame)

pbar.close()
cap.release()
writer.release()

df = pd.DataFrame(csv_rows[1:], columns=csv_rows[0])
df.to_csv(csv_output_path, index=False)
print("Done. Output video:", output_video_path)
print("CSV saved:", csv_output_path)
print("Frames processed:", frame_idx)
print("Time elapsed: %.2fs" % (time.time()-start_time))

from google.colab import files as gfiles
gfiles.download(output_video_path)
gfiles.download(csv_output_path)